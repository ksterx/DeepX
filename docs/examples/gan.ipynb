{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepx.tasks.gan import (\n",
    "    GANModelConfig,\n",
    "    GANTaskConfig,\n",
    "    GANDMConfig,\n",
    "    GANTrainer,\n",
    ")\n",
    "from deepx.tasks.core import DataModuleConfig, TrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = GANModelConfig(\n",
    "    model=\"dcgan\",\n",
    "    latent_dim=100,\n",
    "    base_dim_g=128,\n",
    "    base_dim_d=128,\n",
    "    dropout=0.4,\n",
    "    negative_slope=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_cfg = GANTaskConfig(\n",
    "    lr=1e-4,\n",
    "    loss_fn=\"bce\",\n",
    "    beta1=0.5,\n",
    "    beta2=0.999,\n",
    "    one_side_label_smoothing=0.9,\n",
    "    scheduler=None,\n",
    "    optimizer=\"adam\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_cfg = GANDMConfig(\n",
    "    dm=\"lfw\",\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    train_ratio=0.8,\n",
    "    data_dir=\"/workspace/experiments/data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = TrainingConfig(\n",
    "    ckpt_path=None,\n",
    "    epochs=2,\n",
    "    patience=5,\n",
    "    max_depth=1,\n",
    "    benchmark=True,\n",
    "    debug=False,\n",
    "    monitor_metric=\"val_loss_g\",\n",
    "    monitor_mode=\"min\",\n",
    "    logging=True,\n",
    "    logger=\"mlflow\",\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    root_dir=\"/workspace\",\n",
    "    log_dir=\"/workspace/experiments/mlruns\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GANTrainer(\n",
    "    model_cfg=model_cfg,\n",
    "    task_cfg=task_cfg,\n",
    "    dm_cfg=dm_cfg,\n",
    "    train_cfg=train_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 267823075483077457\n",
      "Run ID: 6323e70b25664aae9d5d9919f39c3c29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Datamodule Config:\n",
      "\tdm: lfw\n",
      "\tdata_dir: /workspace/experiments/data\n",
      "\tbatch_size: 16\n",
      "\tnum_workers: 4\n",
      "\ttrain_ratio: 0.8\n",
      "\tdownload: False\n",
      "==============================\n",
      "Model Config:\n",
      "\tmodel: dcgan\n",
      "\tlatent_dim: 100\n",
      "\tbase_dim_g: 128\n",
      "\tbase_dim_d: 128\n",
      "\tdropout: 0.4\n",
      "\tnegative_slope: 0.1\n",
      "\ttgt_shape: (3, 128, 128)\n",
      "==============================\n",
      "Task Config:\n",
      "\tlr: 0.0001\n",
      "\tloss_fn: bce\n",
      "\toptimizer: adam\n",
      "\tscheduler: None\n",
      "\tbeta1: 0.5\n",
      "\tbeta2: 0.999\n",
      "\tignore_index: -100\n",
      "\tone_side_label_smoothing: 0.9\n",
      "==============================\n",
      "Training Config:\n",
      "\tckpt_path: None\n",
      "\tepochs: 2\n",
      "\tpatience: 5\n",
      "\tmax_depth: 1\n",
      "\tbenchmark: True\n",
      "\tdebug: False\n",
      "\tmonitor_metric: val_loss_g\n",
      "\tmonitor_mode: min\n",
      "\tlogging: True\n",
      "\tlogger: mlflow\n",
      "\taccelerator: auto\n",
      "\tdevices: 1\n",
      "\troot_dir: /workspace\n",
      "\tlog_dir: /workspace/experiments/mlruns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                     | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model         | DCGAN                    | 92.5 M\n",
      "1 | loss_fn       | BCELoss                  | 0     \n",
      "2 | generator     | Generator                | 47.9 M\n",
      "3 | discriminator | Discriminator            | 44.6 M\n",
      "4 | test_metric   | FrechetInceptionDistance | 23.9 M\n",
      "-----------------------------------------------------------\n",
      "92.5 M    Trainable params\n",
      "23.9 M    Non-trainable params\n",
      "116 M     Total params\n",
      "465.271   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.5, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Discriminator optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.5, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3677824f58b5441ea8e7f656b8c4ce56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd5eb4cacc14d01b3ac98841c95c1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a028076c6390446491e6c64258394b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Restoring states from the checkpoint path at ///workspace/experiments/mlruns/267823075483077457/6323e70b25664aae9d5d9919f39c3c29/checkpoints/epoch=1-step=8.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ///workspace/experiments/mlruns/267823075483077457/6323e70b25664aae9d5d9919f39c3c29/checkpoints/epoch=1-step=8.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d74371a22e54ecaaca5f2109c08e4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_fid          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      418.7412109375       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_d_epoch     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8140398263931274     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_loss_fake_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2132731676101685     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_loss_g_epoch     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3527214527130127     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_loss_real_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.41480642557144165    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_fid         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     418.7412109375      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_d_epoch    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8140398263931274    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_loss_fake_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2132731676101685    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_loss_g_epoch    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3527214527130127    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_loss_real_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.41480642557144165   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
