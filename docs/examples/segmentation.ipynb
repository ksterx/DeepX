{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deepx.tasks.segmentation import (\n",
                "    SegmentationModelConfig,\n",
                "    SegmentationConfig,\n",
                "    SegmentationDMConfig,\n",
                "    SegmentationTrainer,\n",
                ")\n",
                "from deepx.tasks.core import TrainingConfig"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_cfg = SegmentationModelConfig(\n",
                "    model=\"unet\",\n",
                "    num_classes=21,\n",
                "    in_channels=3,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "task_cfg = SegmentationConfig(\n",
                "    lr=1e-4,\n",
                "    loss_fn=\"ce\",\n",
                "    optimizer=\"adam\",\n",
                "    scheduler=\"cos\",\n",
                "    beta1=0.9,\n",
                "    beta2=0.999,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm_cfg = SegmentationDMConfig(\n",
                "    dm=\"vocseg\",\n",
                "    batch_size=1,\n",
                "    num_workers=2,\n",
                "    train_ratio=0.8,\n",
                "    data_dir=\"/Users/ksterx/Development/PythonProjects/data\",\n",
                "    download=False,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_cfg = TrainingConfig(\n",
                "    ckpt_path=None,\n",
                "    epochs=2,\n",
                "    patience=5,\n",
                "    max_depth=1,\n",
                "    benchmark=True,\n",
                "    debug=False,\n",
                "    monitor_metric=\"val_loss\",\n",
                "    monitor_mode=\"min\",\n",
                "    logging=True,\n",
                "    logger=\"mlflow\",\n",
                "    accelerator=\"mps\",\n",
                "    devices=None,\n",
                "    root_dir=\"/Users/ksterx/Development/PythonProjects/DeepX\",\n",
                "    log_dir=\"/Users/ksterx/Development/PythonProjects/mlruns\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "train_ratio = 0.8 is passed to deepx.dms.dm/__init__, but it passes through.\n"
                    ]
                }
            ],
            "source": [
                "trainer = SegmentationTrainer(\n",
                "    model_cfg=model_cfg,\n",
                "    task_cfg=task_cfg,\n",
                "    dm_cfg=dm_cfg,\n",
                "    train_cfg=train_cfg,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
                        "GPU available: True (mps), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Experiment ID: 262567696529646416\n",
                        "Run ID: 096a33337fad4032a2f2a087d1243898\n",
                        "==============================\n",
                        "Datamodule Config:\n",
                        "\tdm: vocseg\n",
                        "\tdata_dir: /Users/ksterx/Development/PythonProjects/data\n",
                        "\tbatch_size: 1\n",
                        "\tnum_workers: 2\n",
                        "\ttrain_ratio: 0.8\n",
                        "\tdownload: False\n",
                        "==============================\n",
                        "Model Config:\n",
                        "\tmodel: unet\n",
                        "\tnum_classes: 21\n",
                        "\tin_channels: 3\n",
                        "==============================\n",
                        "Task Config:\n",
                        "\tlr: 0.0001\n",
                        "\tloss_fn: ce\n",
                        "\toptimizer: adam\n",
                        "\tscheduler: cos\n",
                        "\tbeta1: 0.9\n",
                        "\tbeta2: 0.999\n",
                        "\tignore_index: -100\n",
                        "==============================\n",
                        "Training Config:\n",
                        "\tckpt_path: None\n",
                        "\tepochs: 2\n",
                        "\tpatience: 5\n",
                        "\tmax_depth: 1\n",
                        "\tbenchmark: True\n",
                        "\tdebug: False\n",
                        "\tmonitor_metric: val_loss\n",
                        "\tmonitor_mode: min\n",
                        "\tlogging: True\n",
                        "\tlogger: mlflow\n",
                        "\taccelerator: mps\n",
                        "\tdevices: None\n",
                        "\troot_dir: /Users/ksterx/Development/PythonProjects/DeepX\n",
                        "\tlog_dir: /Users/ksterx/Development/PythonProjects/mlruns\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "  | Name      | Type                   | Params\n",
                        "-----------------------------------------------------\n",
                        "0 | model     | UNet                   | 29.0 M\n",
                        "1 | loss_fn   | CrossEntropyLoss       | 0     \n",
                        "2 | train_iou | MulticlassJaccardIndex | 0     \n",
                        "3 | val_iou   | MulticlassJaccardIndex | 0     \n",
                        "4 | test_iou  | MulticlassJaccardIndex | 0     \n",
                        "-----------------------------------------------------\n",
                        "29.0 M    Trainable params\n",
                        "0         Non-trainable params\n",
                        "29.0 M    Total params\n",
                        "115.831   Total estimated model params size (MB)\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
                        "  rank_zero_warn(\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c044cd718621467eb49314a692991786",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9776b32fbb7c4eaeb9110bd357309635",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "874db97e21e44e59998a1c90a5754f59",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
                        "Restoring states from the checkpoint path at ///Users/ksterx/Development/PythonProjects/mlruns/262567696529646416/096a33337fad4032a2f2a087d1243898/checkpoints/epoch=0-step=2.ckpt\n",
                        "Loaded model weights from checkpoint at ///Users/ksterx/Development/PythonProjects/mlruns/262567696529646416/096a33337fad4032a2f2a087d1243898/checkpoints/epoch=0-step=2.ckpt\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "58abd8cea24a4f338357780ae069544b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Testing: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.004241644404828548    </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.8065109252929688     </span>│\n",
                            "└───────────────────────────┴───────────────────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.004241644404828548   \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.8065109252929688    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "└───────────────────────────┴───────────────────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "trainer.train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
