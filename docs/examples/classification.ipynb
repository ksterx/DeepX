{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deepx.tasks.classification import (\n",
                "    ClassificationModelConfig,\n",
                "    ClassificationConfig,\n",
                "    ClassificationDMConfig,\n",
                "    ClassificationTrainer,\n",
                ")\n",
                "from deepx.tasks.core import DataModuleConfig, TrainingConfig\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_cfg = ClassificationModelConfig(model=\"resnet18\", num_classes=10, in_channels=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "task_cfg = ClassificationConfig(\n",
                "    lr=1e-4, loss_fn=\"ce\", optimizer=\"adam\", scheduler=\"cos\", beta1=0.9, beta2=0.999\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm_cfg = ClassificationDMConfig(\n",
                "    dm=\"mnist\",\n",
                "    batch_size=32,\n",
                "    num_workers=2,\n",
                "    train_ratio=0.8,\n",
                "    data_dir=\"/Users/ksterx/Development/PythonProjects/data\",\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_cfg = TrainingConfig(\n",
                "    ckpt_path=None,\n",
                "    epochs=2,\n",
                "    patience=5,\n",
                "    max_depth=1,\n",
                "    benchmark=True,\n",
                "    debug=False,\n",
                "    monitor_metric=\"val_loss\",\n",
                "    monitor_mode=\"min\",\n",
                "    logging=True,\n",
                "    logger=\"mlflow\",\n",
                "    accelerator=\"cpu\",\n",
                "    devices=None,\n",
                "    root_dir=\"/Users/ksterx/Development/PythonProjects/DeepX\",\n",
                "    log_dir=\"/Users/ksterx/Development/PythonProjects/mlruns\",\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer = ClassificationTrainer(\n",
                "    model_cfg=model_cfg, task_cfg=task_cfg, dm_cfg=dm_cfg, train_cfg=train_cfg\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
                        "GPU available: True (mps), used: False\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Experiment ID: 842283682628683223\n",
                        "Run ID: c9504611ef534383a63e426c194855c3\n",
                        "==============================\n",
                        "Datamodule Config:\n",
                        "\tdm: mnist\n",
                        "\tbatch_size: 32\n",
                        "\tnum_workers: 2\n",
                        "\tdata_dir: /Users/ksterx/Development/PythonProjects/data\n",
                        "\ttrain_ratio: 0.8\n",
                        "\tdownload: False\n",
                        "==============================\n",
                        "Model Config:\n",
                        "\tmodel: resnet18\n",
                        "\tnum_classes: 10\n",
                        "\tin_channels: 1\n",
                        "\tdropout: 0.0\n",
                        "==============================\n",
                        "Task Config:\n",
                        "\tlr: 0.0001\n",
                        "\tloss_fn: ce\n",
                        "\toptimizer: adam\n",
                        "\tscheduler: cos\n",
                        "\tbeta1: 0.9\n",
                        "\tbeta2: 0.999\n",
                        "\tignore_index: -100\n",
                        "==============================\n",
                        "Training Config:\n",
                        "\tckpt_path: None\n",
                        "\tepochs: 2\n",
                        "\tpatience: 5\n",
                        "\tmax_depth: 1\n",
                        "\tbenchmark: True\n",
                        "\tdebug: False\n",
                        "\tmonitor_metric: val_loss\n",
                        "\tmonitor_mode: min\n",
                        "\tlogging: True\n",
                        "\tlogger: mlflow\n",
                        "\taccelerator: cpu\n",
                        "\tdevices: None\n",
                        "\troot_dir: /Users/ksterx/Development/PythonProjects/DeepX\n",
                        "\tlog_dir: /Users/ksterx/Development/PythonProjects/mlruns\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
                        "  rank_zero_warn(\n",
                        "\n",
                        "  | Name      | Type               | Params\n",
                        "-------------------------------------------------\n",
                        "0 | model     | ResNet18           | 11.2 M\n",
                        "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
                        "2 | train_acc | MulticlassAccuracy | 0     \n",
                        "3 | val_acc   | MulticlassAccuracy | 0     \n",
                        "4 | test_acc  | MulticlassAccuracy | 0     \n",
                        "-------------------------------------------------\n",
                        "11.2 M    Trainable params\n",
                        "0         Non-trainable params\n",
                        "11.2 M    Total params\n",
                        "44.727    Total estimated model params size (MB)\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
                        "  rank_zero_warn(\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b4a880d59647413e87be0a05f739923d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3682b9f6c73d4c67a18b1b88f57ededd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d875cb5288a94a79b6092c09ae16a5f5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
                        "Restoring states from the checkpoint path at ///Users/ksterx/Development/PythonProjects/mlruns/842283682628683223/c9504611ef534383a63e426c194855c3/checkpoints/epoch=0-step=2.ckpt\n",
                        "Loaded model weights from checkpoint at ///Users/ksterx/Development/PythonProjects/mlruns/842283682628683223/c9504611ef534383a63e426c194855c3/checkpoints/epoch=0-step=2.ckpt\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "63e30fb7e7ef4a7c9198973bf449851b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Testing: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         0.078125          </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.300877571105957     </span>│\n",
                            "└───────────────────────────┴───────────────────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        0.078125         \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.300877571105957    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "└───────────────────────────┴───────────────────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "trainer.train()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
