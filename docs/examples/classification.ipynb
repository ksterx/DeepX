{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deepx.tasks.classification import (\n",
                "    ClassificationModelConfig,\n",
                "    ClassificationConfig,\n",
                "    ClassificationDMConfig,\n",
                "    ClassificationTrainer,\n",
                ")\n",
                "from deepx.tasks.core import DataModuleConfig, TrainingConfig\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_cfg = ClassificationModelConfig(model=\"resnet18\", num_classes=10, in_channels=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "task_cfg = ClassificationConfig(\n",
                "    lr=1e-4, loss_fn=\"ce\", optimizer=\"adam\", scheduler=\"cos\", beta1=0.9, beta2=0.999\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "dm_cfg = ClassificationDMConfig(\n",
                "    dm=\"mnist\",\n",
                "    batch_size=32,\n",
                "    num_workers=2,\n",
                "    train_ratio=0.8,\n",
                "    data_dir=\"/Users/ksterx/Development/PythonProjects/data\",\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_cfg = TrainingConfig(\n",
                "    ckpt_path=None,\n",
                "    epochs=2,\n",
                "    patience=5,\n",
                "    max_depth=1,\n",
                "    benchmark=True,\n",
                "    debug=False,\n",
                "    monitor_metric=\"val_loss\",\n",
                "    monitor_mode=\"min\",\n",
                "    logging=True,\n",
                "    logger=\"mlflow\",\n",
                "    accelerator=\"cpu\",\n",
                "    devices=None,\n",
                "    root_dir=\"/Users/ksterx/Development/PythonProjects/DeepX\",\n",
                "    log_dir=\"/Users/ksterx/Development/PythonProjects/mlruns\",\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer = ClassificationTrainer(\n",
                "    model_cfg=model_cfg, task_cfg=task_cfg, dm_cfg=dm_cfg, train_cfg=train_cfg\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
                        "GPU available: True (mps), used: False\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
                        "  rank_zero_warn(\n",
                        "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==============================\n",
                        "Datamodule Config:\n",
                        "\tdm: mnist\n",
                        "\tbatch_size: 32\n",
                        "\tnum_workers: 2\n",
                        "\tdata_dir: /Users/ksterx/Development/PythonProjects/data\n",
                        "\ttrain_ratio: 0.8\n",
                        "\tdownload: False\n",
                        "==============================\n",
                        "Model Config:\n",
                        "\tmodel: resnet18\n",
                        "\tnum_classes: 10\n",
                        "\tin_channels: 1\n",
                        "\tdropout: 0.0\n",
                        "==============================\n",
                        "Task Config:\n",
                        "\tlr: 0.0001\n",
                        "\tloss_fn: ce\n",
                        "\toptimizer: adam\n",
                        "\tscheduler: cos\n",
                        "\tbeta1: 0.9\n",
                        "\tbeta2: 0.999\n",
                        "\tignore_index: -100\n",
                        "==============================\n",
                        "Training Config:\n",
                        "\tckpt_path: None\n",
                        "\tepochs: 2\n",
                        "\tpatience: 5\n",
                        "\tmax_depth: 1\n",
                        "\tbenchmark: True\n",
                        "\tdebug: True\n",
                        "\tmonitor_metric: val_loss\n",
                        "\tmonitor_mode: min\n",
                        "\tlogging: False\n",
                        "\tlogger: mlflow\n",
                        "\taccelerator: cpu\n",
                        "\tdevices: None\n",
                        "\troot_dir: /Users/ksterx/Development/PythonProjects/DeepX\n",
                        "\tlog_dir: /Users/ksterx/Development/PythonProjects/mlruns\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "  | Name      | Type               | Params\n",
                        "-------------------------------------------------\n",
                        "0 | model     | ResNet18           | 11.2 M\n",
                        "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
                        "2 | train_acc | MulticlassAccuracy | 0     \n",
                        "3 | val_acc   | MulticlassAccuracy | 0     \n",
                        "4 | test_acc  | MulticlassAccuracy | 0     \n",
                        "-------------------------------------------------\n",
                        "11.2 M    Trainable params\n",
                        "0         Non-trainable params\n",
                        "11.2 M    Total params\n",
                        "44.727    Total estimated model params size (MB)\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n",
                        "/Users/ksterx/Development/miniforge3/envs/ai/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d9cc425941cf4ee9a0a01c43cf59ef05",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ac665f323f434234915f6d162484cad2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_steps=1` reached.\n"
                    ]
                }
            ],
            "source": [
                "trainer.train()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
